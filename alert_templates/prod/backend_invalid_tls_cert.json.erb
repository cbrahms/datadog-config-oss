{
  "created_at": 1522790106000,
  "deleted": null,
  "message": "Are the certs out of sync between the control plane and cell block deploys?\nCheck in with routing, this is not good!\n\nWarning: This alert has proven to generate false alarms in the past! (read more for details)\n\nThe reason the alert causes confusion is that it is not specified anywhere that each go-router is reporting its monotonically increasing count of witnessed TLS handshake failures. This means the metric will only grow. Additionally, it can appear spiky due to some routers lacking counts or checking in at less than synchronized intervals.\n\nAlso, the alert triggers in a strange way. It adds up all counts over a 5 minute window, while this alone is not an issue; the rate of reports is about 1 a second across all routers, so if a couple routers have seen one or two errors this thing will go off. (And stay that way until you restart the routers, even if you have fixed the underlying issue.) This also makes it look like the metric is far under the alert threshold on the graph...\n\n[BW]\n- I am attempting to create a better metric but it is unclear if it will actually feel better during a time of stress (aka RED alert).\n- This new metric is also less sensitive; so, I wanted to err on the safe-side and vet it before we committed to it. If these help you during a RED alert, maybe consider replacing the \"Backend TLS invalid cert errors are spiking\" metric with this new one.\nhttps://pivotalcloudopspws.datadoghq.com/monitors#10784390/edit",
  "multi": false,
  "name": "Backend TLS invalid cert errors are spiking",
  "options": {
    "escalation_message": "",
    "include_tags": false,
    "locked": false,
    "new_host_delay": 300,
    "no_data_timeframe": null,
    "notify_audit": false,
    "notify_no_data": false,
    "renotify_interval": 0,
    "require_full_window": true,
    "silenced": {
    },
    "thresholds": {
      "critical": 10.0
    },
    "timeout_h": 0
  },
  "org_id": 4242,
  "overall_state": "OK",
  "overall_state_modified": "2019-08-02T00:21:19+00:00",
  "query": "sum(last_5m):avg:datadog.nozzle.gorouter.backend_invalid_tls_cert{*} >= 10",
  "tags": [

  ],
  "type": "metric alert"
}